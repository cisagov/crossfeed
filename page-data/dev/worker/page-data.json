{"componentChunkName":"component---src-templates-documentation-page-js","path":"/dev/worker/","result":{"data":{"markdownRemark":{"html":"<p>The worker is what runs scans. The code can be found in the <code class=\"language-text\">backend</code> directory.</p>\n<p>When running Crossfeed locally, instances of the worker are launched as Docker containers\nby the <a href=\"scheduler.md\">scheduler</a>. When deployed, every worker instance is launched as a\nFargate task.</p>\n<h3 id=\"directory-structure\" style=\"position:relative;\"><a href=\"#directory-structure\" aria-label=\"directory structure permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Directory structure</h3>\n<p>The <code class=\"language-text\">src/tasks</code> folder contains the code for every scan that the worker supports. <code class=\"language-text\">src/worker.ts</code>\nis the main JavaScript entrypoint for the worker, which picks the right scan to run and runs it.</p>\n<p>The <code class=\"language-text\">Dockerfile.worker</code> file contains the code required to download the right dependencies\nand launch the worker file. It launches <code class=\"language-text\">worker/worker-entry.sh</code>, which sets up MITMProxy\nto sign worker requests and then starts the JavaScript worker entrypoint (<code class=\"language-text\">src/worker.ts</code>).</p>\n<p>The file <code class=\"language-text\">infrastructure/worker.tf</code> contains the Fargate task definition used to launch\nthe worker and the ECR repository used to store the worker's built Dockerfile.</p>\n<p>The file <code class=\"language-text\">tasks/scheduler.ts</code> handles scheduling workers based on existing Scans that\nhave been configured on Crossfeed.</p>\n<p>The file <code class=\"language-text\">tasks/ecs-client.ts</code> handles the task of actually launching workers,\ninterfacing with the Docker API (if local) or the AWS ECS API (if launching on Fargate).</p>\n<h3 id=\"configuration\" style=\"position:relative;\"><a href=\"#configuration\" aria-label=\"configuration permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Configuration</h3>\n<p>To configure properties for the worker, you can modify\nenvironment variables in <code class=\"language-text\">.env</code> in the root directory.</p>\n<p>If you need to configure the worker for deployment, you should update the\n<code class=\"language-text\">env.yml</code> file. You may also need to update parameters in AWS SSM, as several\nenvironment variables use values that are stored in SSM.</p>\n<!-- TODO: document environment variables -->\n<!-- Here is a list of all environment variables:\n\n| Name                            | Description                                                               | Sample value                                  |\n| ------------------------------- | ------------------------------------------------------------------------- | --------------------------------------------- |\n| `REACT_APP_API_URL`             | URL for REST API                                                          | `https://api.staging.crossfeed.cyber.dhs.gov` | -->\n<h3 id=\"scheduling\" style=\"position:relative;\"><a href=\"#scheduling\" aria-label=\"scheduling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Scheduling</h3>\n<p>The <code class=\"language-text\">Scan</code> model represents a scheduled scan that is run on all organizations.\nA scan can be of multiple types -- for example, <code class=\"language-text\">amass</code> , or <code class=\"language-text\">findomain</code> .</p>\n<p>The lambda function <code class=\"language-text\">scheduler.ts</code> goes through each organization and sees which scans\nneed to be run based on their schedule and when they were last run on a particular organization.</p>\n<h3 id=\"scantask\" style=\"position:relative;\"><a href=\"#scantask\" aria-label=\"scantask permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ScanTask</h3>\n<p>The <code class=\"language-text\">ScanTask</code> model represents a single scan task on a single organization and stores the status\nand errors, if any, of that particular task.</p>\n<p>When a scan is run, a <code class=\"language-text\">ScanTask</code> model is created, which launches a Fargate task. When the worker runs, it\nconnects to the database and updates its ScanTask's status accordingly.</p>\n<p>All information needed for the scan (defined in the <code class=\"language-text\">CommandOptions</code> interface) is specified\nthrough the <code class=\"language-text\">CROSSFEED_COMMAND_OPTIONS</code> environment variable. Other secrets needed for the Fargate\ntask to run are specified in the task configuration through Terraform.</p>\n<p>You can view the most recent Scan Tasks, as well as their logs, on the \"Scan History\" page:</p>\n<p>![scan tasks](./img/scan tasks.png)</p>\n<h4 id=\"scantask-status-reference\" style=\"position:relative;\"><a href=\"#scantask-status-reference\" aria-label=\"scantask status reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ScanTask status reference</h4>\n<ul>\n<li><code class=\"language-text\">created</code> : model is created</li>\n<li><code class=\"language-text\">queued</code> : Fargate capacity has been reached, so the task will run whenever there is available capacity.</li>\n<li><code class=\"language-text\">requested</code> : a request to Fargate has been sent to start the task</li>\n<li><code class=\"language-text\">started</code> : the Fargate container has started running the task</li>\n<li><code class=\"language-text\">finished</code> : the Fargate container has finished running the task</li>\n<li><code class=\"language-text\">failed</code> : any of the steps above have failed</li>\n</ul>\n<h3 id=\"running-scans-locally\" style=\"position:relative;\"><a href=\"#running-scans-locally\" aria-label=\"running scans locally permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Running scans locally</h3>\n<p>In order to run scans locally or work on scanning infrastructure,\nyou will need to set up the Fargate worker and rebuild it periodically\nwhen worker code changes.</p>\n<h4 id=\"building-the-worker-docker-image\" style=\"position:relative;\"><a href=\"#building-the-worker-docker-image\" aria-label=\"building the worker docker image permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Building the worker Docker image</h4>\n<p>Each time you make changes to the worker code, you should run the following command to re-build the worker docker image:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">npm</span> run build-worker</code></pre></div>\n<h4 id=\"running-workers-locally\" style=\"position:relative;\"><a href=\"#running-workers-locally\" aria-label=\"running workers locally permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Running workers locally</h4>\n<p>To run a worker locally, just create a scan from the Crossfeed UI.\nWhen running locally, the scheduler function runs every 30 seconds, for convenience, so it will\nstart your worker soon. To manually trigger a run immediately, click on the \"Manually run scheduler\" button on the Scans page.</p>\n<p>Once a worker has started, it is accessible as a running Docker container.\nYou can examine it by running <code class=\"language-text\">docker ps</code> or ( <code class=\"language-text\">docker ps -a | head -n 3</code> for stopped workers ) to view Docker containers.\nand check its logs with <code class=\"language-text\">docker logs [containername]</code> .</p>\n<p>You can check the scheduler logs locally by checking the backend container logs.</p>\n<h4 id=\"generating-censys-types\" style=\"position:relative;\"><a href=\"#generating-censys-types\" aria-label=\"generating censys types permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Generating censys types</h4>\n<p>The <code class=\"language-text\">censysIpv4.ts</code> and <code class=\"language-text\">censysCertificates.ts</code> type files in the <code class=\"language-text\">backend/src/models/generated</code> files have been\nautomatically generated from Censys's published schemas. If you need to re-generate these type files, run:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">npm</span> run codegen</code></pre></div>","frontmatter":{"title":"Worker","sidenav":"dev"},"fields":{"slug":"/dev/worker/"},"headings":[{"value":"Directory structure","depth":3},{"value":"Configuration","depth":3},{"value":"Scheduling","depth":3},{"value":"ScanTask","depth":3},{"value":"ScanTask status reference","depth":4},{"value":"Running scans locally","depth":3},{"value":"Building the worker Docker image","depth":4},{"value":"Running workers locally","depth":4},{"value":"Generating censys types","depth":4}]}},"pageContext":{"name":"/dev/worker/"}},"staticQueryHashes":["1824138477","3841949133","63159454"],"slicesMap":{}}